Login Commands
================
az login
az account set --subscription 87942bd2-87e0-47f3-a71f-f6817369c2ec
az aks get-credentials --resource-group terraform-aks-dev  --name terraform-aks-dev-cluster
cd D:\MyCode\eshop_reference_code\mslearn-microservices-devops-aspnet-core-main\deploy\k8s\ingress-controller
kubectl apply -f nginx-controller.yaml


Silent Commands for remote login bash to build docker
=====================================================
az login --service-principal -u 745395ae-a277-4b78-9d6d-afd9c4680525 -p .AdG1DRSeXcqQSBbE2dJJbg6PZsM.?7] --tenant 38857842-8570-4fcf-870b-b7aa1fcddf06
az account set --subscription 87942bd2-87e0-47f3-a71f-f6817369c2ec
az aks get-credentials --resource-group terraform-aks-dev  --name terraform-aks-dev-cluster



Docker build commands
======================
cd ~
cd /home/priyanko/MyCode/dotnet-autoscaling-code/DemoApi
sudo docker login poc12378acr.azurecr.io --username 0cafbfb9-31b5-4c20-b40f-1ad251ee2dc7 --password T4t8Q~Y2TsB0j-YAZ3Kw2uimS56lNO_nRJc0wcXK
sudo docker build -t poc12378acr.azurecr.io/hpametrics:v1 -f Dockerfile .
sudo docker push poc12378acr.azurecr.io/hpametrics:v1




Commands for remote desktop
============================
kubectl create namespace monitoring
helm uninstall mon -n monitoring
helm install mon --namespace monitoring prometheus-community/kube-prometheus-stack --values C:\MyCode\rootk8s\mykube\prometheus_grafana\prometheus-operator\prom_kube_stack_custom.yaml


helm uninstall my-prometheus-adapter -n monitoring
helm install my-prometheus-adapter prometheus-community/prometheus-adapter -f C:\MyCode\rootk8s\mykube\prometheus_grafana\prometheus-adapter\adapter_values.yaml -n monitoring

kubectl delete -f C:\MyCode\rootk8s\mykube\prometheus_grafana\dotnet-autoscaling-code\DemoApi\k8sDeploy\deploytok8s.yaml -n monitoring
kubectl apply -f C:\MyCode\rootk8s\mykube\prometheus_grafana\dotnet-autoscaling-code\DemoApi\k8sDeploy\deploytok8s.yaml -n monitoring



Commands for local run 
==========================
kubectl create namespace monitoring

# Uninstall and then re-install prometheus operator and grafana from helmchart
# We use 'prom_kube_stack_custom.yaml' to specify additional scraping endpoints like custom metrics endpoints

VERY VERY IMPORTANT !: 
The 'kubernetes_sd_configs' and 'relabel_configs' are key.
They inject namespace and pod name tags with which apis/custom.metrics.k8s.io exposes custom metrics
This is not documented anywhere in internet for exposing custom metrics !
---------------------------------------------------------------------------------

# this is one time activity for pv/pvc setup, no need to run it every time 
# you decidde to uninstall/install prometheus stack
--------------------------------------------------------------------------------
kubectl delete secret generic pv-pvc-secret-monitoring -n monitoring
$STORAGE_KEY=$(az storage account keys list --resource-group storage --account-name priyankoazure --query "[0].value" -o tsv)
kubectl create secret generic pv-pvc-secret-monitoring --from-literal=azurestorageaccountname=priyankoazure --from-literal=azurestorageaccountkey=$STORAGE_KEY -n monitoring -o yaml

kubectl delete -f D:\MyCode\kuberoot\mykube\prometheus_grafana\prometheus-operator\pv-pvc -n monitoring
kubectl apply -f D:\MyCode\kuberoot\mykube\prometheus_grafana\prometheus-operator\pv-pvc -n monitoring


below activity can be performed n times
-------------------------------------
helm uninstall mon -n monitoring
helm install mon --namespace monitoring prometheus-community/kube-prometheus-stack --values D:\MyCode\kuberoot\mykube\prometheus_grafana\prometheus-operator\prom_kube_stack_custom.yaml 

#Ref: https://blog.devops.dev/deploying-kube-prometheus-stack-with-persistent-storage-on-kubernetes-cluster-24473f4ea34f


Uninstall and reinstall prometheus adapter from helm chart
We use adapter_values.yaml to specify metrics query rules that overrides default helm chart settings
---------------------------------------------------------------------------------------
helm uninstall my-prometheus-adapter  -n monitoring
helm install my-prometheus-adapter prometheus-community/prometheus-adapter -f D:\MyCode\kuberoot\mykube\prometheus_grafana\prometheus-adapter\adapter_values.yaml -n monitoring



Unnstall and reinstall custom api pod and hpa that exposes api metrics with /metrics endpoints
----------------------------------------------------------------------------------------
kubectl delete -f D:\MyCode\kuberoot\mykube\prometheus_grafana\k8s-hpa\deploytok8s.yaml -n monitoring
kubectl apply -f D:\MyCode\kuberoot\mykube\prometheus_grafana\k8s-hpa\deploytok8s.yaml -n monitoring

Horizontal pod Autoscaler
--------------------------
kubectl delete -f D:\MyCode\kuberoot\mykube\prometheus_grafana\k8s-hpa\autoscale.yaml -n monitoring
kubectl apply -f D:\MyCode\kuberoot\mykube\prometheus_grafana\k8s-hpa\autoscale.yaml -n monitoring

kubectl get hpa demo-custom-metrics-hpa -n monitoring

Query metric 1
----------------
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq.
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/monitoring/pods/*/my_custom_metric" | jq .

Query metric 2
---------------
kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/monitoring/pods/*/my_app_requests" | jq .



## Use selector to resolve pod name, view pod logs
-----------------------------------------------------
$POD=kubectl get pods --selector=app.kubernetes.io/instance=my-prometheus-adapter -o jsonpath='{.items[0].metadata.name}' -n monitoring 
kubectl logs --since=6m $POD -n monitoring



## Use appname to enter pod shell
------------------------------------
$POD=kubectl get pods -l app=demoapi -o jsonpath='{.items[0].metadata.name}' -n monitoring 
kubectl exec -n monitoring $POD  -it -- /bin/sh
watch -n 5 'seq 1 30 | xargs -n1 -P30  wget  "http://demoapi-service:8000/weatherforecast" &'



Launch prometheus/grafana locally
===================================
kubectl port-forward svc/mon-kube-prometheus-stack-prometheus 9090 --namespace monitoring
kubectl port-forward svc/mon-grafana 80:80 -n monitoring

grafana login
-------------
admin
prom-operator

Horizontal Pod Autoscaler
============================
https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details
From the most basic perspective, the HorizontalPodAutoscaler controller operates on the ratio between
desired metric value and current metric value:


desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]


For example, if the current metric value is 200m, and the desired value is 100m, the number of replicas 
will be doubled, since 200.0 / 100.0 == 2.0 If the current value is instead 50m, you'll halve the number 
of replicas, since 50.0 / 100.0 == 0.5. The control plane skips any scaling action if the ratio is 
sufficiently close to 1.0 (within a globally-configurable tolerance, 0.1 by default).
When a targetAverageValue or targetAverageUtilization is specified, the currentMetricValue is computed by 
taking the average of the given metric across all Pods in the HorizontalPodAutoscaler's scale target.

Scaleup Scaledown behavior
--------------------------
Go through below user stories on hpa scaleup scale down behaviorr, super helpful
https://github.com/kubernetes/enhancements/blob/master/keps/sig-autoscaling/853-configurable-hpa-scale-velocity/README.md#user-stories



Other useful stuff
==================================
seq 1 50 | xargs -n1 -P20  wget  "http://demoapi-service:8000/weatherforecast"
curl http://prometheus-service.monitoring.svc:80/api/v1/series?match%5B%5D=%7B__name__%3D~%22request_duration_seconds_sum%22%7D
curl http://mon-kube-prometheus-stack-prometheus.monitoring.svc:9090/api/v1/series?match%5B%5D=%7B__name__%3D~%22request_duration_seconds_sum%22%7D

wget -O - http://demoapi-service:8000/metrics
wget -O - http://prometheus-service.monitoring.svc
wget -O - http://prometheus-service.monitoring.svc.cluster.local
wget -O - http://prometheus-service.monitoring.svc/api/v1/series?match[]=request_duration_seconds_sum


apt update
apt install curl
seq 1 20 | xargs -n1 -P20  curl  "http://demoapi-service:8000/weatherforecast"

https://github.com/infracloudio/kubernetes-autoscaling/tree/master

https://stackoverflow.com/questions/69617144/prometheus-adapter-empty-item-list-but-successful-http-request


